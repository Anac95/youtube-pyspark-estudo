# ğŸ“Š AnÃ¡lise de Dados do YouTube com PySpark

Este Ã© meu **primeiro projeto utilizando PySpark**, desenvolvido como exercÃ­cio prÃ¡tico para explorar leitura, escrita e manipulaÃ§Ã£o de dados em grandes volumes utilizando a API do Spark.

## ğŸ¯ Objetivo

O projeto simula uma situaÃ§Ã£o real onde um analista de dados precisa:

- Ler arquivos CSV com e sem inferÃªncia de tipos
- Visualizar dados e entender seu esquema
- Escrever dados em formato Parquet
- Criar uma tabela temporÃ¡ria com Spark SQL
- Realizar consultas com SQL no Spark
- Trabalhar com mÃºltiplas fontes de dados (vÃ­deos e comentÃ¡rios)

## ğŸ› ï¸ Tecnologias utilizadas

- Python
- PySpark
- Google Colab

## ğŸ“‚ Estrutura do Projeto

ğŸ“ youtube-pyspark-estudo
â”œâ”€â”€ leitura-escrita.ipynb # Notebook principal do projeto
â”œâ”€â”€ README.md # Este arquivo
â””â”€â”€ data/
â”œâ”€â”€ videos-stats.csv # Dados de estatÃ­sticas de vÃ­deos (amostra)
â””â”€â”€ comments.csv # ComentÃ¡rios dos vÃ­deos (amostra)


## ğŸš€ Como executar

1. Clone este repositÃ³rio ou baixe os arquivos.
2. Abra o notebook `leitura-escrita.ipynb` no [Google Colab](https://colab.research.google.com).
3. FaÃ§a upload dos arquivos `.csv` da pasta `data/` quando solicitado.
4. Execute as cÃ©lulas do notebook e acompanhe o passo a passo.

## ğŸ§  O que aprendi

- Como iniciar um projeto PySpark no Google Colab
- Leitura e escrita de arquivos em diferentes formatos (CSV e Parquet)
- CriaÃ§Ã£o de *DataFrames* e visualizaÃ§Ã£o com `.show()` e `.printSchema()`
- Uso de `createOrReplaceTempView` para consultas SQL
- OrganizaÃ§Ã£o de projetos de dados no GitHub

## ğŸ“Œ ObservaÃ§Ã£o

Os dados usados neste projeto sÃ£o de domÃ­nio pÃºblico (licenÃ§a CC0) e foram reduzidos para fins de estudo. VocÃª pode usÃ¡-los livremente.

---

### ğŸ’¼ Projeto de Estudo â€“ PortfÃ³lio de Dados

Este projeto faz parte do meu aprendizado em **AnÃ¡lise de Dados com PySpark**. Feedbacks sÃ£o bem-vindos!
